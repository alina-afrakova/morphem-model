{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "statistics.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvNBjF6pEt2E",
        "outputId": "40e1e909-8577-431c-82e5-6938a75bb78e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNtXusXBE7fe"
      },
      "source": [
        "## functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qpn3-z7D3Yc"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from enum import Enum\n",
        "\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "\n",
        "SPEECH_PARTS = [\n",
        "    'X',\n",
        "    'ADJ',\n",
        "    'ADV',\n",
        "    'INTJ',\n",
        "    'NOUN',\n",
        "    'PROPN',\n",
        "    'VERB',\n",
        "    'ADP',\n",
        "    'AUX',\n",
        "    'CONJ',\n",
        "    'SCONJ',\n",
        "    'DET',\n",
        "    'NUM',\n",
        "    'PART',\n",
        "    'PRON',\n",
        "    'PUNCT',\n",
        "    'GRND',\n",
        "    'H',\n",
        "    'R',\n",
        "    'Q',\n",
        "    'SYM',\n",
        "]\n",
        "\n",
        "SPEECH_PART_MAPPING = {str(s): num for num, s in enumerate(SPEECH_PARTS)}\n",
        "\n",
        "MASK_VALUE = 0.0\n",
        "\n",
        "MAX_LEN = 20\n",
        "\n",
        "def build_speech_part_array(sp):\n",
        "    output = [0. for _ in range(len(SPEECH_PARTS))]\n",
        "    output[SPEECH_PART_MAPPING[str(sp)]] = 1.\n",
        "    return output\n",
        "\n",
        "\n",
        "CLASSES_NUM = [1, 3, 2, 4, 10, 9, 30, 86, 8, 7, 6, 17, 77, 37, 41, 90, 16, 34,\n",
        "        28, 75, 64, 225, 12, 87, 14, 229, 43, 193, 38, 61, 35, 15, 53, 203, 68,\n",
        "        236, 194, 230, 51, 39, 213, 231, 31, 33, 74, 209, 91, 96, 42, 204, 237,\n",
        "        214, 88, 111, 18, 207, 69, 232, 5, 59, 97, 19, 60, 210, 89, 127, 169,\n",
        "        274, 45, 106, 238, 47, 227, 240, 205, 208, 233, 57, 82, 46, 0]\n",
        "# {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 28, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 45, 46, 47, 51, 53, 57, 59, 60, 61, 64, 68, 69, 74, 75, 77, 82, 86, 87, 88, 89, 90, 91, 96, 97, 106, 111, 127, 169, 193, 194, 203, 204, 205, 207, 208, 209, 210, 213, 214, 225, 227, 229, 230, 231, 232, 233, 236, 237, 238, 240, 274}\n",
        "# set([i for i in range(313 + 1)]) \n",
        "\n",
        "CLASSES_NUM_MAPPING = {cn : num for num, cn in enumerate(CLASSES_NUM)}\n",
        "\n",
        "def build_class_num_array(cn):\n",
        "    output = [0. for _ in range(len(CLASSES_NUM))]\n",
        "    output[CLASSES_NUM_MAPPING[cn]] = 1.\n",
        "    return output\n",
        "\n",
        "\n",
        "PARTS_MAPPING = {\n",
        "    'UNKN': 0,\n",
        "    'PREF': 1,\n",
        "    'ROOT': 2,\n",
        "    'SUFF': 3,\n",
        "    'END': 4,\n",
        "    'LINK': 5,\n",
        "    'HYPH': 6,\n",
        "    'POSTFIX': 7,\n",
        "    'B-SUFF': 8,\n",
        "    'B-PREF': 9,\n",
        "    'B-ROOT': 10,\n",
        "}\n",
        "\n",
        "LETTERS = {\n",
        "    'о': 1,\n",
        "    'е': 2,\n",
        "    'а': 3,\n",
        "    'и': 4,\n",
        "    'н': 5,\n",
        "    'т': 6,\n",
        "    'с': 7,\n",
        "    'р': 8,\n",
        "    'в': 9,\n",
        "    'л': 10,\n",
        "    'к': 11,\n",
        "    'м': 12,\n",
        "    'д': 13,\n",
        "    'п': 14,\n",
        "    'у': 15,\n",
        "    'я': 16,\n",
        "    'ы': 17,\n",
        "    'ь': 18,\n",
        "    'г': 19,\n",
        "    'з': 20,\n",
        "    'б': 21,\n",
        "    'ч': 22,\n",
        "    'й': 23,\n",
        "    'х': 24,\n",
        "    'ж': 25,\n",
        "    'ш': 26,\n",
        "    'ю': 27,\n",
        "    'ц': 28,\n",
        "    'щ': 29,\n",
        "    'э': 30,\n",
        "    'ф': 31,\n",
        "    'ъ': 32,\n",
        "    'ё': 33,\n",
        "    '-': 34,\n",
        "}\n",
        "\n",
        "VOWELS = {\n",
        "    'а', 'и', 'е', 'ё', 'о', 'у', 'ы', 'э', 'ю', 'я'\n",
        "}\n",
        "\n",
        "\n",
        "class MorphemeLabel(Enum):\n",
        "    UNKN = 'UNKN'\n",
        "    PREF = 'PREF'\n",
        "    ROOT = 'ROOT'\n",
        "    SUFF = 'SUFF'\n",
        "    END = 'END'\n",
        "    LINK = 'LINK'\n",
        "    HYPH = 'HYPH'\n",
        "    POSTFIX = 'POSTFIX'\n",
        "    NONE = None\n",
        "\n",
        "\n",
        "class Morpheme(object):\n",
        "    def __init__(self, part_text, label, begin_pos):\n",
        "        self.part_text = part_text\n",
        "        self.length = len(part_text)\n",
        "        self.begin_pos = begin_pos\n",
        "        self.label = label\n",
        "        self.end_pos = self.begin_pos + self.length\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def get_labels(self):\n",
        "        if self.length == 1:\n",
        "            return ['S-' + self.label.value]\n",
        "        result = ['B-' + self.label.value] \n",
        "        result += ['M-' + self.label.value for _ in self.part_text[1:-1]]\n",
        "        result += ['E-' + self.label.value]\n",
        "        return result\n",
        "\n",
        "    def get_simple_labels(self):\n",
        "        if (self.label == MorphemeLabel.SUFF or self.label == MorphemeLabel.PREF or self.label == MorphemeLabel.ROOT):\n",
        "\n",
        "            result = ['B-' + self.label.value]\n",
        "            if self.length > 1:\n",
        "                result += [self.label.value for _ in self.part_text[1:]]\n",
        "            return result\n",
        "        else:\n",
        "            return [self.label.value] * self.length\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.part_text + ':' + self.label.value\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.part_text == other.part_text and self.label == other.label\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(tuple([self.part_text, self.label]))\n",
        "\n",
        "    @property\n",
        "    def unlabeled(self):\n",
        "        return not self.label.value\n",
        "\n",
        "\n",
        "class Word(object):\n",
        "    def __init__(self, morphemes=[], speech_part='X', class_num=0):\n",
        "        self.morphemes = morphemes\n",
        "        self.sp = speech_part\n",
        "        self.class_num = class_num\n",
        "\n",
        "    def append_morpheme(self, morpheme):\n",
        "        self.morphemes.append(morpheme)\n",
        "\n",
        "    def get_word(self):\n",
        "        return ''.join([morpheme.part_text for morpheme in self.morphemes])\n",
        "\n",
        "    def parts_count(self):\n",
        "        return len(self.morphemes)\n",
        "\n",
        "    def morpheme_count(self, morph_label):\n",
        "        return len([morpheme for morpheme in self.morphemes\n",
        "                    if morpheme.label == morph_label])\n",
        "\n",
        "    def morpheme_indexes(self, morph_label):\n",
        "        return [i for i, morpheme in enumerate(self.morphemes)\n",
        "                    if morpheme.label == morph_label]\n",
        "\n",
        "    def get_labels(self):\n",
        "        result = []\n",
        "        for morpheme in self.morphemes:\n",
        "            result += morpheme.get_labels()\n",
        "        return result\n",
        "\n",
        "    def get_simple_labels(self):\n",
        "        result = []\n",
        "        for morpheme in self.morphemes:\n",
        "            result += morpheme.get_simple_labels()\n",
        "        return result\n",
        "\n",
        "    def __str__(self):\n",
        "        return '/'.join([str(morpheme) for morpheme in self.morphemes])\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum(len(m) for m in self.morphemes)\n",
        "\n",
        "    @property\n",
        "    def unlabeled(self):\n",
        "        return all(p.unlabeled for p in self.morphemes)\n",
        "\n",
        "\n",
        "def parse_morpheme(str_repr, position):\n",
        "    #print(str_repr)\n",
        "    text, label = str_repr.split(':')\n",
        "    return Morpheme(text, MorphemeLabel[label], position)\n",
        "\n",
        "\n",
        "def parse_word(str_repr):\n",
        "    if str_repr.count('\\t') == 3:\n",
        "        wordform, word_parts, _, class_info = str_repr.split('\\t')\n",
        "        if 'ADJ' in class_info:\n",
        "            sp = 'ADJ'\n",
        "        elif 'VERB' in class_info:\n",
        "            sp = 'VERB'\n",
        "        elif 'NOUN' in class_info:\n",
        "            sp = 'NOUN'\n",
        "        elif 'GRND' in class_info:\n",
        "            sp = 'GRND'\n",
        "        elif 'ADV' in class_info:\n",
        "            sp = 'ADV'\n",
        "        elif 'PART' in class_info:\n",
        "            sp = 'PART'\n",
        "        else:\n",
        "            raise Exception(\"Unknown class\", class_info)\n",
        "\n",
        "        class_num = int( class_info [class_info.rfind(\" \") + 1 : class_info.rfind(\")\")] )\n",
        "        if class_num not in CLASSES_NUM:\n",
        "            class_num = 1  if sp != 'ADV' else 0\n",
        "\n",
        "    # таких случаев вообще не существует!\n",
        "    elif str_repr.count('\\t') == 2:\n",
        "        wordform, word_parts, sp = str_repr.split('\\t')\n",
        "        class_num = 1\n",
        "    else:\n",
        "        wordform, word_parts = str_repr.split('\\t')\n",
        "        sp, class_num = 'X', 1\n",
        "\n",
        "    if ':' in wordform or '/' in wordform:\n",
        "        return None\n",
        "\n",
        "    parts = word_parts.split('/')\n",
        "    morphemes = []\n",
        "    global_index = 0\n",
        "    for part in parts:\n",
        "        morphemes.append(parse_morpheme(part, global_index))\n",
        "        global_index += len(part)\n",
        "    #if Word(morphemes, sp, class_num).get_word() == 'еры':\n",
        "    #    print(str_repr)\n",
        "    return Word(morphemes, sp, class_num)\n",
        "\n",
        "\n",
        "def divide_word(word):\n",
        "    # Оставляем только слова-прилагательные с одним дефисом \n",
        "    if not (word.sp == 'ADJ' and word.morpheme_count(MorphemeLabel.HYPH) == 1):\n",
        "        return []\n",
        "\n",
        "    morphemes, new_words = [], []\n",
        "    new_word_len = 0\n",
        "    # Дробление слова по дефису\n",
        "    \"\"\"\n",
        "    for i, morpheme in enumerate(word.morphemes):\n",
        "        if morpheme.label == MorphemeLabel.HYPH:\n",
        "            break\n",
        "    \"\"\"\n",
        "    i = word.morpheme_indexes(MorphemeLabel.HYPH) [0]\n",
        "    # Оставляем только слова, у которых перед дефисом стоит морфема о:LINK\n",
        "    if word.morphemes[i-1] != Morpheme('о', MorphemeLabel.LINK, 0):\n",
        "        return []\n",
        "\n",
        "    # sp = 'H' # слово перед дефисом - что-то типо наречия(обозначим как 'H')\n",
        "    # morphemes1 = word.morphemes[:i+1] # берем вместе с дефисом\n",
        "    sp = 'ADV' # слово перед дефисом - наречие\n",
        "    morphemes1 = word.morphemes[:i] # # берем первое слово до дефиса\n",
        "    morphemes2 = word.morphemes[i+1:]\n",
        "    if len(morphemes1) <= MAX_LEN and len(morphemes2) <= MAX_LEN:\n",
        "        new_words.append(Word(morphemes1, sp, 0))\n",
        "        new_words.append(Word(morphemes2, word.sp, word.class_num))\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # Дробление слова по морфемам\n",
        "    for morpheme in word.morphemes:\n",
        "        if new_word_len + len(morpheme) > MAX_LEN:\n",
        "            new_words.append(Word(morphemes, word.sp, word.class_num))\n",
        "            morphemes = [morpheme]\n",
        "            new_word_len = len(morpheme)\n",
        "        else:\n",
        "            morphemes.append(morpheme)\n",
        "            new_word_len += len(morpheme)\n",
        "    new_words.append(Word(morphemes, word.sp, word.class_num))\n",
        "\n",
        "    print(f\"\\nDivide: {word}\")\n",
        "    print(*new_words, sep='\\n')\n",
        "    print()\n",
        "    \"\"\"\n",
        "    return new_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQTjeLYzFGmw"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "eYPNk3o-Eokw",
        "outputId": "837a990f-abdd-467c-f95e-7217462eb594"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    train_set = \"/content/drive/MyDrive/morph_model/tikhonov_lexemes.txt\"\n",
        "\n",
        "    # classes_num_dict = Counter()\n",
        "    # sp_class_num = defaultdict(Counter)\n",
        "\n",
        "    long_words = []\n",
        "\n",
        "    train_part = []\n",
        "    counter = 0\n",
        "    if train_set:\n",
        "        with open(train_set, 'r') as data:\n",
        "            for num, line in enumerate(data):\n",
        "                counter += 1\n",
        "                word = parse_word(line.strip())  if line.strip() != '' else None\n",
        "                if word is None:\n",
        "                    continue\n",
        "                # classes_num_dict [word.class_num] += 1\n",
        "                # sp_class_num [word.sp] [word.class_num] += 1\n",
        "\n",
        "                # train_part.append(word)\n",
        "\n",
        "                if len(word) <= MAX_LEN:\n",
        "                    train_part.append(word)\n",
        "                else:\n",
        "                    long_words.append(word)\n",
        "                '''\n",
        "                    for word in divide_word(word):\n",
        "                        print(word.get_word())\n",
        "                        #train_part.append(word)\n",
        "                '''\n",
        "                if counter % 10000 == 0:\n",
        "                    print(\"Loaded\", counter, \"train words\")\n",
        "                #if counter == 1000: break\n",
        "    \n",
        "    #print(*train_part, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 20000 train words\n",
            "Loaded 40000 train words\n",
            "Loaded 50000 train words\n",
            "Loaded 70000 train words\n",
            "Loaded 80000 train words\n",
            "Loaded 90000 train words\n",
            "Loaded 100000 train words\n",
            "Loaded 110000 train words\n",
            "Loaded 120000 train words\n",
            "Loaded 140000 train words\n",
            "Loaded 150000 train words\n",
            "Loaded 160000 train words\n",
            "Loaded 170000 train words\n",
            "Loaded 180000 train words\n",
            "Loaded 190000 train words\n",
            "Loaded 220000 train words\n",
            "Loaded 230000 train words\n",
            "Loaded 240000 train words\n",
            "Loaded 250000 train words\n",
            "Loaded 260000 train words\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2e845b8407ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-48d4e0e96770>\u001b[0m in \u001b[0;36mparse_word\u001b[0;34m(str_repr)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mclass_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mwordform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_parts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_repr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWIm_i1aQS5B"
      },
      "source": [
        "## Статистика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AIYpp-LGGIl"
      },
      "source": [
        "### Статистика по 'class_num' в общем и его соответсвию конкретной части речи ('speech_part')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7qRWBb4FwV_"
      },
      "source": [
        "    common_classes_num = classes_num_dict.most_common()\n",
        "    print(\"\\nСобранная статистика по class_num (first 20 common):\")\n",
        "    print(*common_classes_num[:20], sep='\\n')\n",
        "    for i in range(20, 100, 20):\n",
        "        print(\"\\nСобранная статистика по class_num (next 20 common):\")\n",
        "        print(*common_classes_num[i : i+20], sep='\\n')\n",
        "    print(\"\\nСобранная статистика по class_num (others):\")\n",
        "    print(*common_classes_num[100:], sep='\\n')\n",
        "\n",
        "    common_classes_num = list(map(lambda x: x[0], common_classes_num[ : 150]))\n",
        "    print(\"CLASSES_NUM:\", common_classes_num[:60])\n",
        "    print(\"CLASSES_NUM:\", common_classes_num[:100])\n",
        "    print(\"CLASSES_NUM:\", common_classes_num[:150])\n",
        "\n",
        "    print(\"\\nspeech part and its class_num:\")\n",
        "    print(*sp_class_num.items(), sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0Jg5dRjGj6D"
      },
      "source": [
        "### Статистика по длиннным словам (> max_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    long_words.sort(key=lambda word: len(word.get_word()), reverse=True)\n",
        "    hyphen_words = list(filter(lambda word: word.morpheme_count(MorphemeLabel.HYPH) > 0, long_words))\n",
        "    link_words = list(filter(lambda word: word.morpheme_count(MorphemeLabel.LINK) > 0 and\n",
        "                            word.morpheme_count(MorphemeLabel.HYPH) == 0, long_words))\n",
        "    \n",
        "    simple_long_words = set(long_words) - set(hyphen_words) - set(link_words)\n",
        "    simple_long_words = sorted(simple_long_words, key=lambda word: len(word.get_word()), reverse=True)\n",
        "\n",
        "    root_count = list(map(lambda word: word.morpheme_count(MorphemeLabel.ROOT), long_words))"
      ],
      "metadata": {
        "id": "zUSprlcSXgDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def equal_lemmas(lexeme1, lexeme2): # равны без окончания\n",
        "    return Word(lexeme1.morphemes[:-1]).get_word() == Word(lexeme2.morphemes[:-1]).get_word() \n",
        "\n",
        "def make_lemmas(lexemes):\n",
        "    lemmas = [lexemes[0]]\n",
        "    for i in range(1, len(lexemes)):\n",
        "        if not equal_lemmas(lexemes[i], lexemes[i - 1]):\n",
        "            lemmas.append(lexemes[i])\n",
        "    return lemmas"
      ],
      "metadata": {
        "id": "2Jeu99J0aFqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(*long_words[0].morphemes[:-1], sep='\\n', end='\\n\\n')\n",
        "long_words[0].morphemes[:-1] == long_words[1].morphemes[:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPLTZN05bIf3",
        "outputId": "98b1ba48-0732-4295-ceca-1ab4283e41bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "брон:ROOT\n",
            "е:LINK\n",
            "бой:ROOT\n",
            "н:SUFF\n",
            "о:LINK\n",
            "-:HYPH\n",
            "за:PREF\n",
            "жиг:ROOT\n",
            "а:SUFF\n",
            "тельн:SUFF\n",
            "о:LINK\n",
            "-:HYPH\n",
            "трасс:ROOT\n",
            "ир:SUFF\n",
            "у:SUFF\n",
            "ющ:SUFF\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[d for d in dir(long_words[0].morphemes[0]) if not d.startswith(\"__\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5zesdDya8Kz",
        "outputId": "0212b364-c811-4ac7-fcb0-3f33ba61ac75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['begin_pos',\n",
              " 'end_pos',\n",
              " 'get_labels',\n",
              " 'get_simple_labels',\n",
              " 'label',\n",
              " 'length',\n",
              " 'part_text',\n",
              " 'unlabeled']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg4s0ivMF1Ee"
      },
      "source": [
        "    output = open(\"/content/drive/MyDrive/morph_model/long_words.txt\", 'w', encoding='utf-8')\n",
        "\n",
        "    print(f\"\\nСобранная статистика по длинным словам (len>{MAX_LEN}):\", file=output)\n",
        "    print(f\"Количество длинных слов: {len(long_words)} ({len(long_words) / (len(long_words) + len(train_part)) * 100 :.2f}% от общей выборки)\", file=output)\n",
        "    print(f\"Среднее количество корней в длинных словах: {sum(root_count) / len(root_count) :.2f}\", file=output)\n",
        "    print(f\"Количество длинных слов через дефис: {len(hyphen_words)} ({len(hyphen_words) / (len(long_words) + len(train_part)) * 100 :.2f}% от общей выборки, {len(hyphen_words) / len(long_words) * 100 :.2f}% от всех длинных слов)\", file=output)\n",
        "    print(f\"Количество длинных слов через соединительную гласную: {len(link_words)} ({len(link_words) / (len(long_words) + len(train_part)) * 100 :.2f}% от общей выборки, {len(link_words) / len(long_words) * 100 :.2f}% от всех длинных слов)\", file=output)\n",
        "    print(f\"Количество длинных слов без дефиса и без соединительной гласной: {len(simple_long_words)} ({len(simple_long_words) / (len(long_words) + len(train_part)) * 100 :.2f}% от общей выборки, {len(simple_long_words) / len(long_words) * 100 :.2f}% от всех длинных слов)\", file=output)\n",
        "\n",
        "\n",
        "    print(\"\\nДлинные слова через дефис:\", file=output)\n",
        "    for word in make_lemmas(hyphen_words[:]):\n",
        "        w = word.get_word()\n",
        "        r = word.morpheme_count(MorphemeLabel.ROOT)\n",
        "        print(f\"(len={len(w)}) (roots={r}) {w}\", file=output)\n",
        "\n",
        "    print(\"\\nДлинные слова через соединительную гласную:\", file=output)\n",
        "    for word in make_lemmas(link_words[:]):\n",
        "        w = word.get_word()\n",
        "        r = word.morpheme_count(MorphemeLabel.ROOT)\n",
        "        print(f\"(len={len(w)}) (roots={r}) {w}\", file=output)\n",
        "\n",
        "    print(\"\\nДлинные слова без дефиса и без соединительной гласной:\", file=output)\n",
        "    for word in make_lemmas(simple_long_words[:]):\n",
        "        w = word.get_word()\n",
        "        r = word.morpheme_count(MorphemeLabel.ROOT)\n",
        "        print(f\"(len={len(w)}) (roots={r}) {w}\", file=output)\n",
        "\n",
        "    output.close()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    long_words_21_22 = list(filter(lambda word: len(word) <= 22, long_words))\n",
        "    hyphen_words_21_22 = list(filter(lambda word: len(word) <= 22, hyphen_words))\n",
        "    link_words_21_22 = list(filter(lambda word: len(word) <= 22, link_words))\n",
        "    simple_long_words_21_22 = list(filter(lambda word: len(word) <= 22, simple_long_words))"
      ],
      "metadata": {
        "id": "YOhZvCn1X3-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    output = open(\"/content/drive/MyDrive/morph_model/long_words_21_22.txt\", 'w', encoding='utf-8')\n",
        "    \n",
        "    print(f\"\\nСобранная статистика по словам длиной 21, 22 ({len(long_words_21_22) / len(long_words) * 100 :.2f}% от всех длинных слов):\", file=output)\n",
        "    print(f\"Количество длинных слов через дефис: {len(hyphen_words_21_22)} ({len(hyphen_words_21_22) / (len(long_words) + len(train_part)) * 100 :.2f}% от общей выборки, \\\n",
        "{len(hyphen_words_21_22) / len(long_words) * 100 :.2f}% от всех длинных слов, \\\n",
        "{len(hyphen_words_21_22) / len(long_words_21_22) * 100 :.2f}% от всех слов длиной 21, 22, \\\n",
        "{len(hyphen_words_21_22) / len(hyphen_words) * 100 :.2f}% от всех слов через дефис)\", file=output)\n",
        "    print(f\"Количество длинных слов через соединительную гласную: {len(link_words_21_22)} ({len(link_words_21_22) / (len(long_words) + len(train_part)) * 100 :.2f}% от общей выборки, \\\n",
        "{len(link_words_21_22) / len(long_words) * 100 :.2f}% от всех длинных слов, \\\n",
        "{len(link_words_21_22) / len(long_words_21_22) * 100 :.2f}% от всех слов длиной 21, 22, \\\n",
        "{len(link_words_21_22) / len(link_words) * 100 :.2f}% от всех слов через соед.гл.)\", file=output)\n",
        "    print(f\"Количество длинных слов без дефиса и без соединительной гласной: {len(simple_long_words_21_22)} ({len(simple_long_words_21_22) / (len(long_words) + len(train_part)) * 100 :.2f}% от общей выборки, \\\n",
        "{len(simple_long_words_21_22) / len(long_words) * 100 :.2f}% от всех длинных слов, \\\n",
        "{len(simple_long_words_21_22) / len(long_words_21_22) * 100 :.2f}% от всех слов длиной 21, 22, \\\n",
        "{len(simple_long_words_21_22) / len(simple_long_words) * 100 :.2f}% от всех слов без дефиса и соед.гл.)\", file=output)\n",
        "\n",
        "\n",
        "    print(\"\\nДлинные слова через дефис:\", file=output)\n",
        "    for word in make_lemmas(hyphen_words_21_22[:]):\n",
        "        w = word.get_word()\n",
        "        r = word.morpheme_count(MorphemeLabel.ROOT)\n",
        "        print(f\"(len={len(w)}) (roots={r}) {w}\", file=output)\n",
        "\n",
        "    print(\"\\nДлинные слова через соединительную гласную:\", file=output)\n",
        "    for word in make_lemmas(link_words_21_22[:]):\n",
        "        w = word.get_word()\n",
        "        r = word.morpheme_count(MorphemeLabel.ROOT)\n",
        "        print(f\"(len={len(w)}) (roots={r}) {w}\", file=output)\n",
        "\n",
        "    print(\"\\nДлинные слова без дефиса и без соединительной гласной:\", file=output)\n",
        "    for word in make_lemmas(simple_long_words_21_22[:]):\n",
        "        w = word.get_word()\n",
        "        r = word.morpheme_count(MorphemeLabel.ROOT)\n",
        "        print(f\"(len={len(w)}) (roots={r}) {w}\", file=output)\n",
        "\n",
        "    output.close()"
      ],
      "metadata": {
        "id": "dCZbFWmsfzb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(long_words_21_22) / (len(long_words) + len(train_part)) * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOD6KqvJo2S9",
        "outputId": "7a9a0403-125c-4345-f39e-4db35bdaff60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7032033164563711"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_b1tlrWGik6"
      },
      "source": [
        "### Статистика по морфемам, которые стоят перед дефисом в длинных словах и на конце наречий"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d9QMMiYF3zo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcacd2e1-d959-4e32-aae5-bf0226f7b7f5"
      },
      "source": [
        "    hyphen_words = list(filter(lambda word: word.morpheme_count(MorphemeLabel.HYPH) == 1 and word.sp == 'ADJ', long_words))\n",
        "    before_hyphen = []\n",
        "    for word in hyphen_words:\n",
        "        i = word.morpheme_indexes(MorphemeLabel.HYPH) [0] # позиция дефиса\n",
        "        before_hyphen.append(word.morphemes[i-1])\n",
        "\n",
        "    print(\"Всевозможные морфемы перед дефисом в длинных словах:\")\n",
        "    for morpheme, i in Counter(before_hyphen).most_common():\n",
        "        print(f\"({i}, {i/len(hyphen_words)*100:.2f}%) {morpheme}\")\n",
        "\n",
        "\n",
        "    adverbs = list(filter(lambda word: word.sp == 'ADV', train_part))\n",
        "    end_adverbs = [word.morphemes[-1] for word in adverbs]\n",
        "\n",
        "    print(\"Всевозможные морфемы на концах наречий:\")\n",
        "    for morpheme, i in Counter(end_adverbs).most_common():\n",
        "        print(f\"({i}, {i/len(adverbs)*100:.2f}%) {morpheme}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всевозможные морфемы перед дефисом в длинных словах:\n",
            "(13098, 96.73%) о:LINK\n",
            "(130, 0.96%) социал:ROOT\n",
            "(53, 0.39%) ал:SUFF\n",
            "(53, 0.39%) ый:END\n",
            "(48, 0.35%) масс:ROOT\n",
            "(24, 0.18%) о:SUFF\n",
            "(24, 0.18%) один:ROOT\n",
            "(24, 0.18%) ово:ROOT\n",
            "(24, 0.18%) е:LINK\n",
            "(24, 0.18%) генерал:ROOT\n",
            "(24, 0.18%) а:SUFF\n",
            "(10, 0.07%) дизель:ROOT\n",
            "(5, 0.04%) флигель:ROOT\n",
            "Всевозможные морфемы на концах наречий:\n",
            "(195, 23.00%) о:END\n",
            "(113, 13.33%) у:SUFF\n",
            "(100, 11.79%) и:END\n",
            "(87, 10.26%) ом:SUFF\n",
            "(64, 7.55%) е:END\n",
            "(64, 7.55%) а:END\n",
            "(24, 2.83%) ую:END\n",
            "(17, 2.00%) ю:END\n",
            "(13, 1.53%) ому:END\n",
            "(11, 1.30%) я:END\n",
            "(10, 1.18%) ком:SUFF\n",
            "(9, 1.06%) нибудь:POSTFIX\n",
            "(8, 0.94%) ой:END\n",
            "(8, 0.94%) ем:SUFF\n",
            "(8, 0.94%) ее:END\n",
            "(7, 0.83%) жды:SUFF\n",
            "(7, 0.83%) либо:POSTFIX\n",
            "(7, 0.83%) ок:SUFF\n",
            "(6, 0.71%) о:SUFF\n",
            "(5, 0.59%) ах:SUFF\n",
            "(5, 0.59%) мя:SUFF\n",
            "(5, 0.59%) ами:END\n",
            "(5, 0.59%) ы:END\n",
            "(3, 0.35%) ем:END\n",
            "(3, 0.35%) а:SUFF\n",
            "(3, 0.35%) ей:SUFF\n",
            "(2, 0.24%) раз:ROOT\n",
            "(2, 0.24%) ам:END\n",
            "(2, 0.24%) сь:POSTFIX\n",
            "(2, 0.24%) ова:SUFF\n",
            "(2, 0.24%) ою:END\n",
            "(2, 0.24%) ость:SUFF\n",
            "(2, 0.24%) е:SUFF\n",
            "(2, 0.24%) я:SUFF\n",
            "(1, 0.12%) чересчур:ROOT\n",
            "(1, 0.12%) т:SUFF\n",
            "(1, 0.12%) сель:ROOT\n",
            "(1, 0.12%) недосуг:ROOT\n",
            "(1, 0.12%) толь:ROOT\n",
            "(1, 0.12%) стремглав:ROOT\n",
            "(1, 0.12%) путем:ROOT\n",
            "(1, 0.12%) резон:ROOT\n",
            "(1, 0.12%) як:SUFF\n",
            "(1, 0.12%) ое:END\n",
            "(1, 0.12%) десят:ROOT\n",
            "(1, 0.12%) у:END\n",
            "(1, 0.12%) друг:ROOT\n",
            "(1, 0.12%) ого:END\n",
            "(1, 0.12%) дцать:SUFF\n",
            "(1, 0.12%) девят:ROOT\n",
            "(1, 0.12%) еж:SUFF\n",
            "(1, 0.12%) шест:ROOT\n",
            "(1, 0.12%) ку:SUFF\n",
            "(1, 0.12%) хрен:ROOT\n",
            "(1, 0.12%) ак:SUFF\n",
            "(1, 0.12%) грех:ROOT\n",
            "(1, 0.12%) ые:SUFF\n",
            "(1, 0.12%) муж:ROOT\n",
            "(1, 0.12%) лень:ROOT\n",
            "(1, 0.12%) пят:ROOT\n",
            "(1, 0.12%) теперь:ROOT\n",
            "(1, 0.12%) ть:SUFF\n",
            "(1, 0.12%) ворот:ROOT\n",
            "(1, 0.12%) сем:ROOT\n",
            "(1, 0.12%) кочень:ROOT\n",
            "(1, 0.12%) мен:ROOT\n",
            "(1, 0.12%) век:ROOT\n",
            "(1, 0.12%) в:SUFF\n",
            "(1, 0.12%) ор:SUFF\n",
            "(1, 0.12%) страх:ROOT\n",
            "(1, 0.12%) круг:ROOT\n",
            "(1, 0.12%) ик:SUFF\n",
            "(1, 0.12%) против:ROOT\n",
            "(1, 0.12%) сплошь:ROOT\n",
            "(1, 0.12%) ль:SUFF\n",
            "(1, 0.12%) ниц:ROOT\n",
            "(1, 0.12%) след:ROOT\n",
            "(1, 0.12%) и:SUFF\n",
            "(1, 0.12%) ум:END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before_hyphen_words = []\n",
        "for word in make_lemmas(hyphen_words):\n",
        "    i = word.morpheme_indexes(MorphemeLabel.HYPH) [0] # позиция дефиса\n",
        "    if word.morphemes[i-1].part_text != 'о' or word.morphemes[i-1].label != MorphemeLabel.LINK:\n",
        "        before_hyphen_words.append(Word(word.morphemes[:]))\n",
        "\n",
        "#before_hyphen_words.sort(key=lambda word: word.morphemes[-1])\n",
        "for word in before_hyphen_words:\n",
        "    print(word.get_word())"
      ],
      "metadata": {
        "id": "U8XJc6PYqWKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898c8c5a-4106-4f67-8be7-8051b2c111c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "социал-предательского\n",
            "масс-спектроскопический\n",
            "национал-социалистский\n",
            "дизель-электроходного\n",
            "социал-соглашательский\n",
            "редукционно-охладительный\n",
            "социал-империалистический\n",
            "стираный-перестираный\n",
            "флигель-адъютантского\n",
            "один-разъединственный\n",
            "планово-организационный\n",
            "социал-империалистский\n",
            "социал-революционного\n",
            "масс-спектрометрический\n",
            "встречный-поперечного\n",
            "социал-патриотический\n",
            "дизель-электрического\n",
            "летне-оздоровительный\n",
            "генерал-губернаторский\n",
            "штопаный-перештопаный\n",
            "гамма-терапевтический\n",
            "национал-демократический\n",
            "социал-демократический\n",
            "национал-либерального\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7PTweQIHD8g"
      },
      "source": [
        "### Статистика по одинаковым словоформам с разными частями речи и/или разными разборами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_tlmDWFHD8q"
      },
      "source": [
        "    repeats = defaultdict(list) # Counter([word.get_word() for word in train_part]).most_common()\n",
        "    for word in train_part:\n",
        "        repeats[word.get_word()]. append((word.sp, str(word)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZCDfI9-S8en"
      },
      "source": [
        "    for word in list(repeats):\n",
        "        repeats[word] = sorted(set(repeats[word]))\n",
        "        if len(repeats[word]) == 1: \n",
        "            repeats.pop(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM0FVi_mMxtt",
        "outputId": "e98cb5d3-fe27-4d68-a103-e90d47666351"
      },
      "source": [
        "    words = set([word.get_word() for word in train_part])\n",
        "    print(f\"Кол-во словоформ, имеющих несколько различных частей речи и/или разборов слова: \\\n",
        "    {len(repeats)} ({len(repeats)/len(words)*100:.2f}% от всех различных слов)\", end='\\n\\n')\n",
        "    for word, pars in list(repeats.items())[:30]:\n",
        "        print(word, *pars, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во словоформ, имеющих несколько различных частей речи и/или разборов слова: 15046 (1.34% от всех различных слов)\n",
            "\n",
            "передняя\n",
            "('ADJ', 'перед:ROOT/н:SUFF/яя:END')\n",
            "('NOUN', 'перед:ROOT/н:SUFF/яя:END')\n",
            "передней\n",
            "('ADJ', 'перед:ROOT/н:SUFF/ей:END')\n",
            "('NOUN', 'перед:ROOT/н:SUFF/ей:END')\n",
            "переднюю\n",
            "('ADJ', 'перед:ROOT/н:SUFF/юю:END')\n",
            "('NOUN', 'перед:ROOT/н:SUFF/юю:END')\n",
            "('VERB', 'пере:PREF/дн:ROOT/ю:SUFF/ю:END')\n",
            "жила\n",
            "('NOUN', 'жил:ROOT/а:END')\n",
            "('VERB', 'жи:ROOT/л:SUFF/а:END')\n",
            "жилой\n",
            "('ADJ', 'жи:ROOT/л:SUFF/ой:END')\n",
            "('NOUN', 'жил:ROOT/ой:END')\n",
            "фрезерно-центровальный\n",
            "('ADJ', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ый:END')\n",
            "('NOUN', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ый:END')\n",
            "фрезерно-центровального\n",
            "('ADJ', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ого:END')\n",
            "('NOUN', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ого:END')\n",
            "фрезерно-центровальному\n",
            "('ADJ', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ому:END')\n",
            "('NOUN', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ому:END')\n",
            "фрезерно-центровальным\n",
            "('ADJ', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ым:END')\n",
            "('NOUN', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ы:END/м:END')\n",
            "('NOUN', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ым:END')\n",
            "фрезерно-центровальном\n",
            "('ADJ', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ом:END')\n",
            "('NOUN', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ом:END')\n",
            "радиально-сверлильный\n",
            "('ADJ', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ый:END')\n",
            "('NOUN', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ый:END')\n",
            "радиально-сверлильного\n",
            "('ADJ', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ого:END')\n",
            "('NOUN', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ого:END')\n",
            "радиально-сверлильному\n",
            "('ADJ', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ому:END')\n",
            "('NOUN', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ому:END')\n",
            "радиально-сверлильным\n",
            "('ADJ', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ым:END')\n",
            "('NOUN', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ы:END/м:END')\n",
            "('NOUN', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ым:END')\n",
            "радиально-сверлильном\n",
            "('ADJ', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ом:END')\n",
            "('NOUN', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ом:END')\n",
            "лужу\n",
            "('NOUN', 'луж:ROOT/у:END')\n",
            "('VERB', 'луж:ROOT/у:END')\n",
            "прели\n",
            "('NOUN', 'пре:ROOT/л:SUFF/и:END')\n",
            "('VERB', 'пре:ROOT/л:SUFF/и:END')\n",
            "светлейшим\n",
            "('NOUN', 'свет:ROOT/л:SUFF/ейш:SUFF/и:END/м:END')\n",
            "('NOUN', 'свет:ROOT/л:SUFF/ейш:SUFF/им:END')\n",
            "морильни\n",
            "('NOUN', 'мор:ROOT/и:SUFF/ль:SUFF/н:SUFF/и:END')\n",
            "('NOUN', 'мор:ROOT/и:SUFF/льн:SUFF/и:END')\n",
            "пампасский\n",
            "('ADJ', 'пампас:ROOT/ск:SUFF/ий:END')\n",
            "('NOUN', 'пампас:ROOT/ск:SUFF/ий:END')\n",
            "пампасского\n",
            "('ADJ', 'пампас:ROOT/ск:SUFF/ого:END')\n",
            "('NOUN', 'пампас:ROOT/ск:SUFF/ого:END')\n",
            "пампасскому\n",
            "('ADJ', 'пампас:ROOT/ск:SUFF/ому:END')\n",
            "('NOUN', 'пампас:ROOT/ск:SUFF/ому:END')\n",
            "пампасским\n",
            "('ADJ', 'пампас:ROOT/ск:SUFF/им:END')\n",
            "('NOUN', 'пампас:ROOT/ск:SUFF/и:END/м:END')\n",
            "('NOUN', 'пампас:ROOT/ск:SUFF/им:END')\n",
            "пампасском\n",
            "('ADJ', 'пампас:ROOT/ск:SUFF/ом:END')\n",
            "('NOUN', 'пампас:ROOT/ск:SUFF/ом:END')\n",
            "комплексно-механизированный\n",
            "('ADJ', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ый:END')\n",
            "('NOUN', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ый:END')\n",
            "комплексно-механизированного\n",
            "('ADJ', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ого:END')\n",
            "('NOUN', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ого:END')\n",
            "комплексно-механизированному\n",
            "('ADJ', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ому:END')\n",
            "('NOUN', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ому:END')\n",
            "комплексно-механизированным\n",
            "('ADJ', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ым:END')\n",
            "('NOUN', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ы:END/м:END')\n",
            "('NOUN', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ым:END')\n",
            "комплексно-механизированном\n",
            "('ADJ', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ом:END')\n",
            "('NOUN', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ом:END')\n",
            "полуголодный\n",
            "('ADJ', 'пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ый:END')\n",
            "('NOUN', 'пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ый:END')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvb8bUvuXjli",
        "outputId": "e412e70b-b81f-4996-9753-ca628b5b057f"
      },
      "source": [
        "    diff_POS = Counter([tuple(zip(*l))[0] for l in repeats.values()])\n",
        "    \n",
        "    print(f\"Кол-во различных вариантов нескольких частей речи для одной словоформы (всего: {len(diff_POS)}):\", end='\\n\\n')\n",
        "    summ = sum(diff_POS.values())\n",
        "    for POS, count in diff_POS.most_common():\n",
        "        print(f\"{POS} - {count} ({count/summ*100:.2f}%)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во различных вариантов нескольких частей речи для одной словоформы (всего: 29):\n",
            "\n",
            "('ADJ', 'NOUN') - 9856 (65.51%)\n",
            "('ADJ', 'NOUN', 'NOUN') - 1232 (8.19%)\n",
            "('NOUN', 'NOUN') - 1141 (7.58%)\n",
            "('ADJ', 'PART') - 1101 (7.32%)\n",
            "('NOUN', 'VERB') - 754 (5.01%)\n",
            "('VERB', 'VERB') - 543 (3.61%)\n",
            "('GRND', 'NOUN') - 145 (0.96%)\n",
            "('ADV', 'NOUN') - 99 (0.66%)\n",
            "('ADJ', 'ADJ') - 55 (0.37%)\n",
            "('ADJ', 'GRND') - 27 (0.18%)\n",
            "('ADJ', 'ADJ', 'NOUN') - 20 (0.13%)\n",
            "('ADJ', 'VERB') - 16 (0.11%)\n",
            "('NOUN', 'VERB', 'VERB') - 7 (0.05%)\n",
            "('ADV', 'GRND') - 7 (0.05%)\n",
            "('GRND', 'VERB') - 7 (0.05%)\n",
            "('ADJ', 'NOUN', 'PART') - 6 (0.04%)\n",
            "('GRND', 'GRND') - 6 (0.04%)\n",
            "('PART', 'PART') - 5 (0.03%)\n",
            "('ADV', 'VERB') - 4 (0.03%)\n",
            "('ADJ', 'NOUN', 'VERB') - 2 (0.01%)\n",
            "('ADJ', 'ADJ', 'NOUN', 'NOUN') - 2 (0.01%)\n",
            "('NOUN', 'NOUN', 'NOUN') - 2 (0.01%)\n",
            "('NOUN', 'NOUN', 'VERB') - 2 (0.01%)\n",
            "('ADJ', 'ADV') - 2 (0.01%)\n",
            "('ADV', 'NOUN', 'VERB') - 1 (0.01%)\n",
            "('ADJ', 'ADV', 'NOUN') - 1 (0.01%)\n",
            "('ADJ', 'NOUN', 'NOUN', 'VERB') - 1 (0.01%)\n",
            "('GRND', 'NOUN', 'NOUN') - 1 (0.01%)\n",
            "('VERB', 'VERB', 'VERB') - 1 (0.01%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVlKvd3UiLAp"
      },
      "source": [
        "def run_length_encoding(x):\n",
        "    \"\"\"\n",
        "    Make run-length encoding.\n",
        "    The first one contains numbers, and the second one - how many times they need to be repeated.\n",
        "    x = [2, 2, 2, 3, 3, 3, 5, 2] -> [2, 3, 5, 2], [3, 3, 1, 1]\n",
        "    \"\"\"\n",
        "    i, num, rep = 0, [], []\n",
        "    while i < len(x):\n",
        "        num.append(x[i])\n",
        "        rep.append(0)\n",
        "        while i < len(x) and x[i] == num[-1]:\n",
        "            rep[-1] += 1\n",
        "            i += 1\n",
        "    return num, rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGIDXl-qYIxD",
        "outputId": "eff136c3-98c8-4008-e4ea-e2aeca537a10"
      },
      "source": [
        "    same_POS_diff_parsing = defaultdict(list)\n",
        "    for word in repeats:\n",
        "        POS, parsing = list(zip(*repeats[word]))\n",
        "        POS, rep = run_length_encoding(POS)\n",
        "        for i, pos in enumerate(POS):\n",
        "            if rep[i] != 1:\n",
        "                j = sum(rep[:i])\n",
        "                same_POS_diff_parsing[word]. append((pos, parsing[j : j+rep[i]]))\n",
        "\n",
        "    print(f\"Кол-во словоформ, имеющих несколько различных разборов слова для одной части речи: \\\n",
        "    {len(same_POS_diff_parsing)} ({len(same_POS_diff_parsing)/len(words)*100:.2f}% от всех различных слов)\", end='\\n\\n')\n",
        "    for word, pars in list(same_POS_diff_parsing.items())[:30]:\n",
        "        print(word)\n",
        "        for p in pars:\n",
        "            print(p[0])\n",
        "            print(*p[1], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во словоформ, имеющих несколько различных разборов слова для одной части речи: 3018 (0.27% от всех различных слов)\n",
            "\n",
            "фрезерно-центровальным\n",
            "NOUN\n",
            "фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ы:END/м:END\n",
            "фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ым:END\n",
            "радиально-сверлильным\n",
            "NOUN\n",
            "ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ы:END/м:END\n",
            "ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ым:END\n",
            "светлейшим\n",
            "NOUN\n",
            "свет:ROOT/л:SUFF/ейш:SUFF/и:END/м:END\n",
            "свет:ROOT/л:SUFF/ейш:SUFF/им:END\n",
            "морильни\n",
            "NOUN\n",
            "мор:ROOT/и:SUFF/ль:SUFF/н:SUFF/и:END\n",
            "мор:ROOT/и:SUFF/льн:SUFF/и:END\n",
            "пампасским\n",
            "NOUN\n",
            "пампас:ROOT/ск:SUFF/и:END/м:END\n",
            "пампас:ROOT/ск:SUFF/им:END\n",
            "комплексно-механизированным\n",
            "NOUN\n",
            "комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ы:END/м:END\n",
            "комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ым:END\n",
            "полуголодным\n",
            "NOUN\n",
            "пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ы:END/м:END\n",
            "пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ым:END\n",
            "сборно-щитовым\n",
            "NOUN\n",
            "с:PREF/бор:ROOT/н:SUFF/о:LINK/-:HYPH/щит:ROOT/ов:SUFF/ы:END/м:END\n",
            "с:PREF/бор:ROOT/н:SUFF/о:LINK/-:HYPH/щит:ROOT/ов:SUFF/ым:END\n",
            "сукномойки\n",
            "NOUN\n",
            "сукн:ROOT/о:LINK/мой:ROOT/к:SUFF/и:END\n",
            "сукн:ROOT/о:LINK/мойк:ROOT/и:END\n",
            "сербскохорватско-русским\n",
            "NOUN\n",
            "серб:ROOT/ск:SUFF/о:LINK/хорват:ROOT/ск:SUFF/о:LINK/-:HYPH/рус:ROOT/ск:SUFF/и:END/м:END\n",
            "серб:ROOT/ск:SUFF/о:LINK/хорват:ROOT/ск:SUFF/о:LINK/-:HYPH/рус:ROOT/ск:SUFF/им:END\n",
            "автоподстройки\n",
            "NOUN\n",
            "авто:ROOT/под:PREF/строй:ROOT/к:SUFF/и:END\n",
            "авто:ROOT/под:PREF/стройк:ROOT/и:END\n",
            "судейско-информационным\n",
            "NOUN\n",
            "суд:ROOT/ей:SUFF/ск:SUFF/о:LINK/-:HYPH/информ:ROOT/аци:SUFF/онн:SUFF/ы:END/м:END\n",
            "суд:ROOT/ей:SUFF/ск:SUFF/о:LINK/-:HYPH/информ:ROOT/аци:SUFF/онн:SUFF/ым:END\n",
            "аграрно-индустриальным\n",
            "NOUN\n",
            "аграр:ROOT/н:SUFF/о:LINK/-:HYPH/индустри:ROOT/альн:SUFF/ы:END/м:END\n",
            "аграр:ROOT/н:SUFF/о:LINK/-:HYPH/индустри:ROOT/альн:SUFF/ым:END\n",
            "классово-эксплуататорским\n",
            "NOUN\n",
            "класс:ROOT/ов:SUFF/о:LINK/-:HYPH/эксплуат:ROOT/атор:SUFF/ск:SUFF/и:END/м:END\n",
            "класс:ROOT/ов:SUFF/о:LINK/-:HYPH/эксплуат:ROOT/атор:SUFF/ск:SUFF/им:END\n",
            "ленточки\n",
            "NOUN\n",
            "лент:ROOT/оч:SUFF/к:SUFF/и:END\n",
            "лент:ROOT/очк:SUFF/и:END\n",
            "волосинки\n",
            "NOUN\n",
            "волос:ROOT/ин:SUFF/к:SUFF/и:END\n",
            "волос:ROOT/инк:SUFF/и:END\n",
            "ваттным\n",
            "NOUN\n",
            "ватт:ROOT/н:SUFF/ы:END/м:END\n",
            "ватт:ROOT/н:SUFF/ым:END\n",
            "токарно-револьверным\n",
            "NOUN\n",
            "ток:ROOT/ар:SUFF/н:SUFF/о:LINK/-:HYPH/револьвер:ROOT/н:SUFF/ы:END/м:END\n",
            "ток:ROOT/ар:SUFF/н:SUFF/о:LINK/-:HYPH/револьвер:ROOT/н:SUFF/ым:END\n",
            "однодиапазонным\n",
            "NOUN\n",
            "одн:ROOT/о:LINK/диапазон:ROOT/н:SUFF/ы:END/м:END\n",
            "одн:ROOT/о:LINK/диапазон:ROOT/н:SUFF/ым:END\n",
            "приклейки\n",
            "NOUN\n",
            "при:PREF/клей:ROOT/к:SUFF/и:END\n",
            "при:PREF/клейк:ROOT/и:END\n",
            "кумушки\n",
            "NOUN\n",
            "кум:ROOT/уш:SUFF/к:SUFF/и:END\n",
            "кум:ROOT/ушк:SUFF/и:END\n",
            "сопроводиловки\n",
            "NOUN\n",
            "со:PREF/про:PREF/вод:ROOT/и:SUFF/л:SUFF/ов:SUFF/к:SUFF/и:END\n",
            "со:PREF/про:PREF/вод:ROOT/и:SUFF/л:SUFF/овк:SUFF/и:END\n",
            "анархо-синдикалистским\n",
            "NOUN\n",
            "анарх:ROOT/о:LINK/-:HYPH/синдикал:ROOT/ист:SUFF/ск:SUFF/и:END/м:END\n",
            "анарх:ROOT/о:LINK/-:HYPH/синдикал:ROOT/ист:SUFF/ск:SUFF/им:END\n",
            "плавки\n",
            "NOUN\n",
            "пла:ROOT/в:SUFF/к:SUFF/и:END\n",
            "плав:ROOT/к:SUFF/и:END\n",
            "полуслова\n",
            "NOUN\n",
            "пол:ROOT/у:SUFF/слов:ROOT/а:END\n",
            "полу:ROOT/слов:SUFF/а:END\n",
            "полуслову\n",
            "NOUN\n",
            "пол:ROOT/у:SUFF/слов:ROOT/у:END\n",
            "полу:ROOT/слов:SUFF/у:END\n",
            "полусловом\n",
            "NOUN\n",
            "пол:ROOT/у:SUFF/слов:ROOT/ом:END\n",
            "полу:ROOT/слов:SUFF/ом:END\n",
            "полуслове\n",
            "NOUN\n",
            "пол:ROOT/у:SUFF/слов:ROOT/е:END\n",
            "полу:ROOT/слов:SUFF/е:END\n",
            "щегловки\n",
            "NOUN\n",
            "щегл:ROOT/ов:SUFF/к:SUFF/и:END\n",
            "щегл:ROOT/овк:SUFF/и:END\n",
            "кооперативно-колхозным\n",
            "NOUN\n",
            "коопер:ROOT/ат:SUFF/ив:SUFF/н:SUFF/о:LINK/-:HYPH/кол:ROOT/хоз:ROOT/н:SUFF/ы:END/м:END\n",
            "коопер:ROOT/ат:SUFF/ив:SUFF/н:SUFF/о:LINK/-:HYPH/кол:ROOT/хоз:ROOT/н:SUFF/ым:END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkqh4CHtmdQV",
        "outputId": "da560541-0947-4311-83c7-3ef3173eb4fa"
      },
      "source": [
        "    same_POS = Counter([tuple([l[0][0]])*len(l[0][1]) if len(l) == 1 else tuple(sorted(tuple([l[0][0]])*len(l[0][1]) + tuple([l[1][0]])*len(l[1][1])))\n",
        "                        for l in same_POS_diff_parsing.values()])\n",
        "    \n",
        "    summ = sum(same_POS.values())\n",
        "    print(\"Варианты одинаковых частей речи для одной словоформы с различными разборами слова:\")\n",
        "    for POS, count in same_POS.most_common():\n",
        "        print(f\"{POS} - {count} ({count/summ*100:.2f}%)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Варианты одинаковых частей речи для одной словоформы с различными разборами слова:\n",
            "('NOUN', 'NOUN') - 2377 (78.76%)\n",
            "('VERB', 'VERB') - 550 (18.22%)\n",
            "('ADJ', 'ADJ') - 75 (2.49%)\n",
            "('GRND', 'GRND') - 6 (0.20%)\n",
            "('PART', 'PART') - 5 (0.17%)\n",
            "('ADJ', 'ADJ', 'NOUN', 'NOUN') - 2 (0.07%)\n",
            "('NOUN', 'NOUN', 'NOUN') - 2 (0.07%)\n",
            "('VERB', 'VERB', 'VERB') - 1 (0.03%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN07jj4PGbX8",
        "outputId": "46433533-74e2-44ae-d64e-bb349581671c"
      },
      "source": [
        "for word in same_POS_diff_parsing:\n",
        "    if same_POS_diff_parsing[word][0][0] == 'PART':\n",
        "        print(word)\n",
        "        print(*same_POS_diff_parsing[word][0][1], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "обобьющий\n",
            "о:PREF/бобь:ROOT/ющ:SUFF/ий:END\n",
            "обо:PREF/бь:ROOT/ющ:SUFF/ий:END\n",
            "попрущий\n",
            "по:PREF/пру:ROOT/щий:END\n",
            "попр:ROOT/ущ:SUFF/ий:END\n",
            "обобьющийся\n",
            "о:PREF/бобь:ROOT/ющ:SUFF/ий:END/ся:POSTFIX\n",
            "обо:PREF/бь:ROOT/ющ:SUFF/ий:END/ся:POSTFIX\n",
            "охающий\n",
            "о:PREF/ха:ROOT/ющ:SUFF/ий:END\n",
            "ох:ROOT/а:SUFF/ющ:SUFF/ий:END\n",
            "стающий\n",
            "с:PREF/та:ROOT/ющ:SUFF/ий:END\n",
            "ста:ROOT/ющ:SUFF/ий:END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHh_3BC-p2Y9",
        "outputId": "2c994d32-1d20-4dee-9d46-3220d10b1529"
      },
      "source": [
        "for word in same_POS_diff_parsing:\n",
        "    if len(same_POS_diff_parsing[word][0][1]) >= 3:\n",
        "        print(word, same_POS_diff_parsing[word])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "шейки [('NOUN', ('ше:ROOT/йк:SUFF/и:END', 'шей:ROOT/к:SUFF/и:END', 'шейк:ROOT/и:END'))]\n",
            "тельца [('NOUN', ('тел:ROOT/ьц:SUFF/а:END', 'тель:ROOT/ц:SUFF/а:END', 'тельц:ROOT/а:END'))]\n",
            "смели [('VERB', ('с:PREF/ме:ROOT/л:SUFF/и:END', 'с:PREF/мел:ROOT/и:END', 'сме:ROOT/л:SUFF/и:END'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MernwUiSsds5",
        "outputId": "fc586827-5cef-48c7-ffe3-4b456980ec06"
      },
      "source": [
        "for word in same_POS_diff_parsing:\n",
        "    if len(same_POS_diff_parsing[word]) == 2:\n",
        "        print(word, *same_POS_diff_parsing[word], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "взводным\n",
            "('ADJ', ('вз:PREF/вод:ROOT/н:SUFF/ым:END', 'взвод:ROOT/н:SUFF/ым:END'))\n",
            "('NOUN', ('взвод:ROOT/н:SUFF/ы:END/м:END', 'взвод:ROOT/н:SUFF/ым:END'))\n",
            "половой\n",
            "('ADJ', ('пол:ROOT/ов:SUFF/ой:END', 'полов:ROOT/ой:END'))\n",
            "('NOUN', ('пол:ROOT/ов:SUFF/ой:END', 'полов:ROOT/ой:END'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwSJOy8nuloz",
        "outputId": "54201a06-b116-49b7-82eb-4b16085420fb"
      },
      "source": [
        "    diff_POS_same_parsing = defaultdict(list)\n",
        "    for word in repeats:\n",
        "        POS, parsing = sorted(zip(*repeats[word]), key=lambda x: x[1])\n",
        "        parsing, rep = run_length_encoding(parsing)\n",
        "        for i, pars in enumerate(parsing):\n",
        "            if rep[i] != 1:\n",
        "                j = sum(rep[:i])\n",
        "                diff_POS_same_parsing[word]. append((pars, POS[j : j+rep[i]]))\n",
        "\n",
        "    print(f\"Кол-во словоформ, имеющих несколько различных частей речи для одноого разбора: \\\n",
        "    {len(diff_POS_same_parsing)} ({len(diff_POS_same_parsing)/len(words)*100:.2f}% от всех различных слов)\", end='\\n\\n')\n",
        "    print(*list(diff_POS_same_parsing.items())[:50], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во словоформ, имеющих несколько различных частей речи для одноого разбора: 7601 (0.68% от всех различных слов)\n",
            "\n",
            "('передняя', [('перед:ROOT/н:SUFF/яя:END', ('ADJ', 'NOUN'))])\n",
            "('передней', [('перед:ROOT/н:SUFF/ей:END', ('ADJ', 'NOUN'))])\n",
            "('переднюю', [('перед:ROOT/н:SUFF/юю:END', ('ADJ', 'NOUN'))])\n",
            "('фрезерно-центровальный', [('фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ый:END', ('ADJ', 'NOUN'))])\n",
            "('фрезерно-центровального', [('фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('фрезерно-центровальному', [('фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('фрезерно-центровальном', [('фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('радиально-сверлильный', [('ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ый:END', ('ADJ', 'NOUN'))])\n",
            "('радиально-сверлильного', [('ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('радиально-сверлильному', [('ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('радиально-сверлильном', [('ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('лужу', [('луж:ROOT/у:END', ('NOUN', 'VERB'))])\n",
            "('прели', [('пре:ROOT/л:SUFF/и:END', ('NOUN', 'VERB'))])\n",
            "('пампасский', [('пампас:ROOT/ск:SUFF/ий:END', ('ADJ', 'NOUN'))])\n",
            "('пампасского', [('пампас:ROOT/ск:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('пампасскому', [('пампас:ROOT/ск:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('пампасском', [('пампас:ROOT/ск:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('комплексно-механизированный', [('комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ый:END', ('ADJ', 'NOUN'))])\n",
            "('комплексно-механизированного', [('комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('комплексно-механизированному', [('комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('комплексно-механизированном', [('комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('полуголодный', [('пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ый:END', ('ADJ', 'NOUN'))])\n",
            "('полуголодного', [('пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('полуголодному', [('пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('полуголодном', [('пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('сборно-щитовой', [('с:PREF/бор:ROOT/н:SUFF/о:LINK/-:HYPH/щит:ROOT/ов:SUFF/ой:END', ('ADJ', 'NOUN'))])\n",
            "('сборно-щитового', [('с:PREF/бор:ROOT/н:SUFF/о:LINK/-:HYPH/щит:ROOT/ов:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('сборно-щитовому', [('с:PREF/бор:ROOT/н:SUFF/о:LINK/-:HYPH/щит:ROOT/ов:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('сборно-щитовом', [('с:PREF/бор:ROOT/н:SUFF/о:LINK/-:HYPH/щит:ROOT/ов:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('строчила', [('строч:ROOT/и:SUFF/л:SUFF/а:END', ('NOUN', 'VERB'))])\n",
            "('сербскохорватско-русский', [('серб:ROOT/ск:SUFF/о:LINK/хорват:ROOT/ск:SUFF/о:LINK/-:HYPH/рус:ROOT/ск:SUFF/ий:END', ('ADJ', 'NOUN'))])\n",
            "('сербскохорватско-русского', [('серб:ROOT/ск:SUFF/о:LINK/хорват:ROOT/ск:SUFF/о:LINK/-:HYPH/рус:ROOT/ск:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('сербскохорватско-русскому', [('серб:ROOT/ск:SUFF/о:LINK/хорват:ROOT/ск:SUFF/о:LINK/-:HYPH/рус:ROOT/ск:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('сербскохорватско-русском', [('серб:ROOT/ск:SUFF/о:LINK/хорват:ROOT/ск:SUFF/о:LINK/-:HYPH/рус:ROOT/ск:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('судейско-информационный', [('суд:ROOT/ей:SUFF/ск:SUFF/о:LINK/-:HYPH/информ:ROOT/аци:SUFF/онн:SUFF/ый:END', ('ADJ', 'NOUN'))])\n",
            "('судейско-информационного', [('суд:ROOT/ей:SUFF/ск:SUFF/о:LINK/-:HYPH/информ:ROOT/аци:SUFF/онн:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('судейско-информационному', [('суд:ROOT/ей:SUFF/ск:SUFF/о:LINK/-:HYPH/информ:ROOT/аци:SUFF/онн:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('судейско-информационном', [('суд:ROOT/ей:SUFF/ск:SUFF/о:LINK/-:HYPH/информ:ROOT/аци:SUFF/онн:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('аграрно-индустриальный', [('аграр:ROOT/н:SUFF/о:LINK/-:HYPH/индустри:ROOT/альн:SUFF/ый:END', ('ADJ', 'NOUN'))])\n",
            "('аграрно-индустриального', [('аграр:ROOT/н:SUFF/о:LINK/-:HYPH/индустри:ROOT/альн:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('аграрно-индустриальному', [('аграр:ROOT/н:SUFF/о:LINK/-:HYPH/индустри:ROOT/альн:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('аграрно-индустриальном', [('аграр:ROOT/н:SUFF/о:LINK/-:HYPH/индустри:ROOT/альн:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('классово-эксплуататорский', [('класс:ROOT/ов:SUFF/о:LINK/-:HYPH/эксплуат:ROOT/атор:SUFF/ск:SUFF/ий:END', ('ADJ', 'NOUN'))])\n",
            "('классово-эксплуататорского', [('класс:ROOT/ов:SUFF/о:LINK/-:HYPH/эксплуат:ROOT/атор:SUFF/ск:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('классово-эксплуататорскому', [('класс:ROOT/ов:SUFF/о:LINK/-:HYPH/эксплуат:ROOT/атор:SUFF/ск:SUFF/ому:END', ('ADJ', 'NOUN'))])\n",
            "('классово-эксплуататорском', [('класс:ROOT/ов:SUFF/о:LINK/-:HYPH/эксплуат:ROOT/атор:SUFF/ск:SUFF/ом:END', ('ADJ', 'NOUN'))])\n",
            "('пошив', [('по:PREF/ши:ROOT/в:SUFF', ('GRND', 'NOUN'))])\n",
            "('ваттный', [('ватт:ROOT/н:SUFF/ый:END', ('ADJ', 'NOUN'))])\n",
            "('ваттного', [('ватт:ROOT/н:SUFF/ого:END', ('ADJ', 'NOUN'))])\n",
            "('ваттному', [('ватт:ROOT/н:SUFF/ому:END', ('ADJ', 'NOUN'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3vqSuhj7HXB",
        "outputId": "d42e8447-6938-4707-ebbe-d3dedf1388bd"
      },
      "source": [
        "    same_parsing = Counter([l[0][1] for l in diff_POS_same_parsing.values()])\n",
        "    \n",
        "    print(\"Варианты разных частей речи для одной словоформы с одинаковыми разборами слова:\")\n",
        "    summ = sum(same_parsing.values())\n",
        "    for POS, count in same_parsing.most_common():\n",
        "        print(f\"{POS} - {count} ({count/summ*100:.2f}%)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Варианты разных частей речи для одной словоформы с одинаковыми разборами слова:\n",
            "('ADJ', 'NOUN') - 6014 (79.12%)\n",
            "('ADJ', 'PART') - 1009 (13.27%)\n",
            "('NOUN', 'VERB') - 484 (6.37%)\n",
            "('GRND', 'NOUN') - 41 (0.54%)\n",
            "('ADV', 'NOUN') - 37 (0.49%)\n",
            "('GRND', 'VERB') - 7 (0.09%)\n",
            "('ADJ', 'NOUN', 'PART') - 5 (0.07%)\n",
            "('ADJ', 'VERB') - 3 (0.04%)\n",
            "('ADV', 'VERB') - 1 (0.01%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z5qv7Sp81Bo",
        "outputId": "1cb956db-f1cf-434d-e448-6ec3459f3601"
      },
      "source": [
        "    for word in diff_POS_same_parsing:\n",
        "        if diff_POS_same_parsing[word][0][1] == ('ADJ', 'VERB') or diff_POS_same_parsing[word][0][1] == ('ADV', 'VERB'):\n",
        "            print(word, diff_POS_same_parsing[word])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "княжим [('княж:ROOT/им:END', ('ADJ', 'VERB'))]\n",
            "горячим [('горяч:ROOT/им:END', ('ADJ', 'VERB'))]\n",
            "синим [('син:ROOT/им:END', ('ADJ', 'VERB'))]\n",
            "сродни [('с:PREF/родн:ROOT/и:END', ('ADV', 'VERB'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLqvJHZ39bhz",
        "outputId": "ec441935-a665-4bf9-ae96-f1f84f4d8d4b"
      },
      "source": [
        "    for word in diff_POS_same_parsing:\n",
        "        if len(diff_POS_same_parsing[word][0][1]) == 3:\n",
        "            print(word, diff_POS_same_parsing[word])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "председательствующий [('председатель:ROOT/ств:SUFF/у:SUFF/ющ:SUFF/ий:END', ('ADJ', 'NOUN', 'PART'))]\n",
            "замыкающий [('за:PREF/мык:ROOT/а:SUFF/ющ:SUFF/ий:END', ('ADJ', 'NOUN', 'PART'))]\n",
            "командующий [('команд:ROOT/у:SUFF/ющ:SUFF/ий:END', ('ADJ', 'NOUN', 'PART'))]\n",
            "успевающий [('успе:ROOT/ва:SUFF/ющ:SUFF/ий:END', ('ADJ', 'NOUN', 'PART'))]\n",
            "разводящий [('раз:PREF/вод:ROOT/ящ:SUFF/ий:END', ('ADJ', 'NOUN', 'PART'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMmpZZTyv2h4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de1c7e0-8eb8-4834-b8fc-8a03411ddf9c"
      },
      "source": [
        "    diff_POS_diff_parsing = defaultdict(list)\n",
        "    for word in repeats:\n",
        "        for i in range(len(repeats[word])-1):\n",
        "            for j in range(i+1, len(repeats[word])):\n",
        "                if repeats[word][i][0] != repeats[word][j][0] and repeats[word][i][1] != repeats[word][j][1]:\n",
        "                    diff_POS_diff_parsing[word]. append(tuple(zip(repeats[word][i], repeats[word][j])))\n",
        "    \n",
        "    print(f\"Кол-во словоформ, имеющих несколько различных разборов слова для различных частей речи соответственно: \\\n",
        "    {len(diff_POS_diff_parsing)} ({len(diff_POS_diff_parsing)/len(words)*100:.2f}% от всех различных слов)\", end='\\n\\n')\n",
        "    # print(*list(diff_POS_diff_parsing.items())[:50], sep='\\n')\n",
        "    for word, pars in list(diff_POS_diff_parsing.items())[:30]:\n",
        "        print(word)\n",
        "        for p in pars:\n",
        "            print(*zip(*p), sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во словоформ, имеющих несколько различных разборов слова для различных частей речи соответственно: 5702 (0.51% от всех различных слов)\n",
            "\n",
            "переднюю\n",
            "('ADJ', 'перед:ROOT/н:SUFF/юю:END')\n",
            "('VERB', 'пере:PREF/дн:ROOT/ю:SUFF/ю:END')\n",
            "('NOUN', 'перед:ROOT/н:SUFF/юю:END')\n",
            "('VERB', 'пере:PREF/дн:ROOT/ю:SUFF/ю:END')\n",
            "жила\n",
            "('NOUN', 'жил:ROOT/а:END')\n",
            "('VERB', 'жи:ROOT/л:SUFF/а:END')\n",
            "жилой\n",
            "('ADJ', 'жи:ROOT/л:SUFF/ой:END')\n",
            "('NOUN', 'жил:ROOT/ой:END')\n",
            "фрезерно-центровальным\n",
            "('ADJ', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ым:END')\n",
            "('NOUN', 'фрез:ROOT/ер:SUFF/н:SUFF/о:LINK/-:HYPH/центр:ROOT/ова:SUFF/ль:SUFF/н:SUFF/ы:END/м:END')\n",
            "радиально-сверлильным\n",
            "('ADJ', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ым:END')\n",
            "('NOUN', 'ради:ROOT/альн:SUFF/о:LINK/-:HYPH/сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/ы:END/м:END')\n",
            "пампасским\n",
            "('ADJ', 'пампас:ROOT/ск:SUFF/им:END')\n",
            "('NOUN', 'пампас:ROOT/ск:SUFF/и:END/м:END')\n",
            "комплексно-механизированным\n",
            "('ADJ', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ым:END')\n",
            "('NOUN', 'комплекс:ROOT/н:SUFF/о:LINK/-:HYPH/механ:ROOT/из:SUFF/ир:SUFF/ова:SUFF/нн:SUFF/ы:END/м:END')\n",
            "полуголодным\n",
            "('ADJ', 'пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ым:END')\n",
            "('NOUN', 'пол:ROOT/у:SUFF/голод:ROOT/н:SUFF/ы:END/м:END')\n",
            "сборно-щитовым\n",
            "('ADJ', 'с:PREF/бор:ROOT/н:SUFF/о:LINK/-:HYPH/щит:ROOT/ов:SUFF/ым:END')\n",
            "('NOUN', 'с:PREF/бор:ROOT/н:SUFF/о:LINK/-:HYPH/щит:ROOT/ов:SUFF/ы:END/м:END')\n",
            "сербскохорватско-русским\n",
            "('ADJ', 'серб:ROOT/ск:SUFF/о:LINK/хорват:ROOT/ск:SUFF/о:LINK/-:HYPH/рус:ROOT/ск:SUFF/им:END')\n",
            "('NOUN', 'серб:ROOT/ск:SUFF/о:LINK/хорват:ROOT/ск:SUFF/о:LINK/-:HYPH/рус:ROOT/ск:SUFF/и:END/м:END')\n",
            "судейско-информационным\n",
            "('ADJ', 'суд:ROOT/ей:SUFF/ск:SUFF/о:LINK/-:HYPH/информ:ROOT/аци:SUFF/онн:SUFF/ым:END')\n",
            "('NOUN', 'суд:ROOT/ей:SUFF/ск:SUFF/о:LINK/-:HYPH/информ:ROOT/аци:SUFF/онн:SUFF/ы:END/м:END')\n",
            "аграрно-индустриальным\n",
            "('ADJ', 'аграр:ROOT/н:SUFF/о:LINK/-:HYPH/индустри:ROOT/альн:SUFF/ым:END')\n",
            "('NOUN', 'аграр:ROOT/н:SUFF/о:LINK/-:HYPH/индустри:ROOT/альн:SUFF/ы:END/м:END')\n",
            "классово-эксплуататорским\n",
            "('ADJ', 'класс:ROOT/ов:SUFF/о:LINK/-:HYPH/эксплуат:ROOT/атор:SUFF/ск:SUFF/им:END')\n",
            "('NOUN', 'класс:ROOT/ов:SUFF/о:LINK/-:HYPH/эксплуат:ROOT/атор:SUFF/ск:SUFF/и:END/м:END')\n",
            "ваттным\n",
            "('ADJ', 'ватт:ROOT/н:SUFF/ым:END')\n",
            "('NOUN', 'ватт:ROOT/н:SUFF/ы:END/м:END')\n",
            "токарно-револьверным\n",
            "('ADJ', 'ток:ROOT/ар:SUFF/н:SUFF/о:LINK/-:HYPH/револьвер:ROOT/н:SUFF/ым:END')\n",
            "('NOUN', 'ток:ROOT/ар:SUFF/н:SUFF/о:LINK/-:HYPH/револьвер:ROOT/н:SUFF/ы:END/м:END')\n",
            "слезу\n",
            "('NOUN', 'слез:ROOT/у:END')\n",
            "('VERB', 'с:PREF/лез:ROOT/у:END')\n",
            "однодиапазонным\n",
            "('ADJ', 'одн:ROOT/о:LINK/диапазон:ROOT/н:SUFF/ым:END')\n",
            "('NOUN', 'одн:ROOT/о:LINK/диапазон:ROOT/н:SUFF/ы:END/м:END')\n",
            "анархо-синдикалистским\n",
            "('ADJ', 'анарх:ROOT/о:LINK/-:HYPH/синдикал:ROOT/ист:SUFF/ск:SUFF/им:END')\n",
            "('NOUN', 'анарх:ROOT/о:LINK/-:HYPH/синдикал:ROOT/ист:SUFF/ск:SUFF/и:END/м:END')\n",
            "кооперативно-колхозным\n",
            "('ADJ', 'коопер:ROOT/ат:SUFF/ив:SUFF/н:SUFF/о:LINK/-:HYPH/кол:ROOT/хоз:ROOT/н:SUFF/ым:END')\n",
            "('NOUN', 'коопер:ROOT/ат:SUFF/ив:SUFF/н:SUFF/о:LINK/-:HYPH/кол:ROOT/хоз:ROOT/н:SUFF/ы:END/м:END')\n",
            "выем\n",
            "('NOUN', 'вы:PREF/ем:ROOT')\n",
            "('VERB', 'вы:PREF/е:ROOT/м:END')\n",
            "выпью\n",
            "('NOUN', 'выпь:ROOT/ю:END')\n",
            "('VERB', 'вы:PREF/пь:ROOT/ю:END')\n",
            "высотно-компенсирующим\n",
            "('ADJ', 'выс:ROOT/от:SUFF/н:SUFF/о:LINK/-:HYPH/компенс:ROOT/ир:SUFF/у:SUFF/ющ:SUFF/им:END')\n",
            "('NOUN', 'выс:ROOT/от:SUFF/н:SUFF/о:LINK/-:HYPH/компенс:ROOT/ир:SUFF/у:SUFF/ющ:SUFF/и:END/м:END')\n",
            "рокированным\n",
            "('ADJ', 'рок:ROOT/ир:SUFF/ова:SUFF/нн:SUFF/ым:END')\n",
            "('NOUN', 'рок:ROOT/ир:SUFF/ова:SUFF/нн:SUFF/ы:END/м:END')\n",
            "малоактуальным\n",
            "('ADJ', 'мал:ROOT/о:LINK/актуаль:ROOT/н:SUFF/ым:END')\n",
            "('NOUN', 'мал:ROOT/о:LINK/актуаль:ROOT/н:SUFF/ы:END/м:END')\n",
            "множимым\n",
            "('ADJ', 'множ:ROOT/им:SUFF/ым:END')\n",
            "('NOUN', 'множ:ROOT/им:SUFF/ы:END/м:END')\n",
            "сверлильно-фрезерным\n",
            "('ADJ', 'сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/о:LINK/-:HYPH/фрез:ROOT/ер:SUFF/н:SUFF/ым:END')\n",
            "('NOUN', 'сверл:ROOT/и:SUFF/ль:SUFF/н:SUFF/о:LINK/-:HYPH/фрез:ROOT/ер:SUFF/н:SUFF/ы:END/м:END')\n",
            "четырехмоторным\n",
            "('ADJ', 'четыр:ROOT/ех:SUFF/мотор:ROOT/н:SUFF/ым:END')\n",
            "('NOUN', 'четыр:ROOT/ех:SUFF/мотор:ROOT/н:SUFF/ы:END/м:END')\n",
            "учебно-показательным\n",
            "('ADJ', 'уч:ROOT/еб:SUFF/н:SUFF/о:LINK/-:HYPH/показ:ROOT/а:SUFF/тельн:SUFF/ым:END')\n",
            "('NOUN', 'уч:ROOT/еб:SUFF/н:SUFF/о:LINK/-:HYPH/показ:ROOT/а:SUFF/тельн:SUFF/ы:END/м:END')\n",
            "научно-координационным\n",
            "('ADJ', 'на:PREF/уч:ROOT/н:SUFF/о:LINK/-:HYPH/координ:ROOT/аци:SUFF/онн:SUFF/ым:END')\n",
            "('NOUN', 'на:PREF/уч:ROOT/н:SUFF/о:LINK/-:HYPH/координ:ROOT/аци:SUFF/онн:SUFF/ы:END/м:END')\n",
            "спиртобензольным\n",
            "('ADJ', 'спирт:ROOT/о:LINK/бенз:ROOT/оль:SUFF/н:SUFF/ым:END')\n",
            "('NOUN', 'спирт:ROOT/о:LINK/бенз:ROOT/оль:SUFF/н:SUFF/ы:END/м:END')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yFgkjZfAmzu",
        "outputId": "667c4ed1-adce-41aa-c7f5-72380fa47d89"
      },
      "source": [
        "    diff_parsing = Counter([tuple(zip(*l))[0] for l in diff_POS_diff_parsing.values()])\n",
        "    \n",
        "    print(\"Варианты разных частей речи для одной словоформы с различными разборами слова:\")\n",
        "    summ = sum(diff_parsing.values())\n",
        "    for POS, count in diff_parsing.most_common():\n",
        "        print(f\"{POS} - {count} ({count/summ*100:.2f}%)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Варианты разных частей речи для одной словоформы с различными разборами слова:\n",
            "(('ADJ', 'NOUN'),) - 5093 (89.32%)\n",
            "(('NOUN', 'VERB'),) - 276 (4.84%)\n",
            "(('GRND', 'NOUN'),) - 106 (1.86%)\n",
            "(('ADJ', 'PART'),) - 92 (1.61%)\n",
            "(('ADV', 'NOUN'),) - 63 (1.10%)\n",
            "(('ADJ', 'GRND'),) - 27 (0.47%)\n",
            "(('ADJ', 'VERB'),) - 13 (0.23%)\n",
            "(('ADJ', 'NOUN'), ('ADJ', 'NOUN')) - 10 (0.18%)\n",
            "(('ADV', 'GRND'),) - 7 (0.12%)\n",
            "(('NOUN', 'VERB'), ('NOUN', 'VERB')) - 3 (0.05%)\n",
            "(('ADV', 'VERB'),) - 3 (0.05%)\n",
            "(('ADJ', 'VERB'), ('NOUN', 'VERB')) - 2 (0.04%)\n",
            "(('ADJ', 'ADV'),) - 2 (0.04%)\n",
            "(('ADJ', 'NOUN'), ('ADJ', 'NOUN'), ('ADJ', 'NOUN')) - 1 (0.02%)\n",
            "(('ADV', 'VERB'), ('NOUN', 'VERB')) - 1 (0.02%)\n",
            "(('ADJ', 'ADV'), ('ADV', 'NOUN')) - 1 (0.02%)\n",
            "(('ADJ', 'NOUN'), ('ADJ', 'VERB'), ('NOUN', 'VERB'), ('NOUN', 'VERB')) - 1 (0.02%)\n",
            "(('ADJ', 'PART'), ('NOUN', 'PART')) - 1 (0.02%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rUmJUBgDP_4",
        "outputId": "ba6ac533-7b3e-49d5-8f29-938ca44034f7"
      },
      "source": [
        "    for word in diff_POS_diff_parsing:\n",
        "        if diff_POS_diff_parsing[word][0][0] == ('ADJ', 'ADV'):\n",
        "            print(word, *zip(*diff_POS_diff_parsing[word][0]), sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "броском\n",
            "('ADJ', 'брос:ROOT/к:SUFF/ом:END')\n",
            "('ADV', 'брос:ROOT/к:SUFF/ом:SUFF')\n",
            "добром\n",
            "('ADJ', 'добр:ROOT/ом:END')\n",
            "('ADV', 'добр:ROOT/ом:SUFF')\n",
            "стойком\n",
            "('ADJ', 'стой:ROOT/к:SUFF/ом:END')\n",
            "('ADV', 'стой:ROOT/ком:SUFF')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwaGNOrPHZne",
        "outputId": "1122e433-8947-46ee-b193-29046e5bc1a0"
      },
      "source": [
        "    for word in diff_POS_diff_parsing:\n",
        "        if len(diff_POS_diff_parsing[word]) >= 3:\n",
        "            print(word, *diff_POS_diff_parsing[word], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "взводным\n",
            "(('ADJ', 'NOUN'), ('вз:PREF/вод:ROOT/н:SUFF/ым:END', 'взвод:ROOT/н:SUFF/ы:END/м:END'))\n",
            "(('ADJ', 'NOUN'), ('вз:PREF/вод:ROOT/н:SUFF/ым:END', 'взвод:ROOT/н:SUFF/ым:END'))\n",
            "(('ADJ', 'NOUN'), ('взвод:ROOT/н:SUFF/ым:END', 'взвод:ROOT/н:SUFF/ы:END/м:END'))\n",
            "ловчим\n",
            "(('ADJ', 'NOUN'), ('лов:ROOT/ч:SUFF/им:END', 'лов:ROOT/ч:SUFF/и:END/м:END'))\n",
            "(('ADJ', 'VERB'), ('лов:ROOT/ч:SUFF/им:END', 'ловч:ROOT/им:END'))\n",
            "(('NOUN', 'VERB'), ('лов:ROOT/ч:SUFF/и:END/м:END', 'ловч:ROOT/им:END'))\n",
            "(('NOUN', 'VERB'), ('лов:ROOT/ч:SUFF/им:END', 'ловч:ROOT/им:END'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oASuCmMUKSQq",
        "outputId": "e8b4ca3f-54ff-4ce9-cb13-3fcb31c54ce0"
      },
      "source": [
        "    for word in diff_POS_diff_parsing:\n",
        "        if len(diff_POS_diff_parsing[word]) == 2:\n",
        "            print(word)\n",
        "            for pars in diff_POS_diff_parsing[word]:\n",
        "                print(*zip(*pars), sep='\\n', end='\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "переднюю\n",
            "('ADJ', 'перед:ROOT/н:SUFF/юю:END')\n",
            "('VERB', 'пере:PREF/дн:ROOT/ю:SUFF/ю:END')\n",
            "\n",
            "('NOUN', 'перед:ROOT/н:SUFF/юю:END')\n",
            "('VERB', 'пере:PREF/дн:ROOT/ю:SUFF/ю:END')\n",
            "\n",
            "порой\n",
            "('ADV', 'пор:ROOT/ой:END')\n",
            "('VERB', 'по:PREF/ро:ROOT/й:END')\n",
            "\n",
            "('NOUN', 'пор:ROOT/ой:END')\n",
            "('VERB', 'по:PREF/ро:ROOT/й:END')\n",
            "\n",
            "повести\n",
            "('NOUN', 'повест:ROOT/и:END')\n",
            "('VERB', 'по:PREF/вес:ROOT/ти:END')\n",
            "\n",
            "('NOUN', 'повест:ROOT/и:END')\n",
            "('VERB', 'по:PREF/вест:ROOT/и:END')\n",
            "\n",
            "броском\n",
            "('ADJ', 'брос:ROOT/к:SUFF/ом:END')\n",
            "('ADV', 'брос:ROOT/к:SUFF/ом:SUFF')\n",
            "\n",
            "('ADV', 'брос:ROOT/к:SUFF/ом:SUFF')\n",
            "('NOUN', 'брос:ROOT/к:SUFF/ом:END')\n",
            "\n",
            "извести\n",
            "('NOUN', 'извест:ROOT/и:END')\n",
            "('VERB', 'из:PREF/вест:ROOT/и:END')\n",
            "\n",
            "('NOUN', 'извест:ROOT/и:END')\n",
            "('VERB', 'извес:ROOT/ти:END')\n",
            "\n",
            "нападающий\n",
            "('ADJ', 'напад:ROOT/а:SUFF/ющ:SUFF/ий:END')\n",
            "('PART', 'на:PREF/пад:ROOT/а:SUFF/ющ:SUFF/ий:END')\n",
            "\n",
            "('NOUN', 'напад:ROOT/а:SUFF/ющ:SUFF/ий:END')\n",
            "('PART', 'на:PREF/пад:ROOT/а:SUFF/ющ:SUFF/ий:END')\n",
            "\n",
            "половой\n",
            "('ADJ', 'пол:ROOT/ов:SUFF/ой:END')\n",
            "('NOUN', 'полов:ROOT/ой:END')\n",
            "\n",
            "('ADJ', 'полов:ROOT/ой:END')\n",
            "('NOUN', 'пол:ROOT/ов:SUFF/ой:END')\n",
            "\n",
            "жарким\n",
            "('ADJ', 'жарк:ROOT/им:END')\n",
            "('NOUN', 'жар:ROOT/к:SUFF/и:END/м:END')\n",
            "\n",
            "('ADJ', 'жарк:ROOT/им:END')\n",
            "('NOUN', 'жар:ROOT/к:SUFF/им:END')\n",
            "\n",
            "взводные\n",
            "('ADJ', 'вз:PREF/вод:ROOT/н:SUFF/ые:END')\n",
            "('NOUN', 'взвод:ROOT/н:SUFF/ы:END/е:END')\n",
            "\n",
            "('ADJ', 'взвод:ROOT/н:SUFF/ые:END')\n",
            "('NOUN', 'взвод:ROOT/н:SUFF/ы:END/е:END')\n",
            "\n",
            "взводных\n",
            "('ADJ', 'вз:PREF/вод:ROOT/н:SUFF/ых:END')\n",
            "('NOUN', 'взвод:ROOT/н:SUFF/ы:END/х:END')\n",
            "\n",
            "('ADJ', 'взвод:ROOT/н:SUFF/ых:END')\n",
            "('NOUN', 'взвод:ROOT/н:SUFF/ы:END/х:END')\n",
            "\n",
            "взводными\n",
            "('ADJ', 'вз:PREF/вод:ROOT/н:SUFF/ыми:END')\n",
            "('NOUN', 'взвод:ROOT/н:SUFF/ы:END/ми:END')\n",
            "\n",
            "('ADJ', 'взвод:ROOT/н:SUFF/ыми:END')\n",
            "('NOUN', 'взвод:ROOT/н:SUFF/ы:END/ми:END')\n",
            "\n",
            "синей\n",
            "('ADJ', 'син:ROOT/ей:END')\n",
            "('VERB', 'син:ROOT/е:SUFF/й:END')\n",
            "\n",
            "('NOUN', 'син:ROOT/ей:END')\n",
            "('VERB', 'син:ROOT/е:SUFF/й:END')\n",
            "\n",
            "кубовые\n",
            "('ADJ', 'куб:ROOT/ов:SUFF/ые:END')\n",
            "('NOUN', 'куб:ROOT/ов:SUFF/ы:END/е:END')\n",
            "\n",
            "('ADJ', 'кубов:ROOT/ые:END')\n",
            "('NOUN', 'куб:ROOT/ов:SUFF/ы:END/е:END')\n",
            "\n",
            "кубовых\n",
            "('ADJ', 'куб:ROOT/ов:SUFF/ых:END')\n",
            "('NOUN', 'куб:ROOT/ов:SUFF/ы:END/х:END')\n",
            "\n",
            "('ADJ', 'кубов:ROOT/ых:END')\n",
            "('NOUN', 'куб:ROOT/ов:SUFF/ы:END/х:END')\n",
            "\n",
            "кубовым\n",
            "('ADJ', 'куб:ROOT/ов:SUFF/ым:END')\n",
            "('NOUN', 'куб:ROOT/ов:SUFF/ы:END/м:END')\n",
            "\n",
            "('ADJ', 'кубов:ROOT/ым:END')\n",
            "('NOUN', 'куб:ROOT/ов:SUFF/ы:END/м:END')\n",
            "\n",
            "кубовыми\n",
            "('ADJ', 'куб:ROOT/ов:SUFF/ыми:END')\n",
            "('NOUN', 'куб:ROOT/ов:SUFF/ы:END/ми:END')\n",
            "\n",
            "('ADJ', 'кубов:ROOT/ыми:END')\n",
            "('NOUN', 'куб:ROOT/ов:SUFF/ы:END/ми:END')\n",
            "\n",
            "купчих\n",
            "('ADJ', 'куп:ROOT/ч:SUFF/их:END')\n",
            "('NOUN', 'куп:ROOT/ч:SUFF/и:END/х:END')\n",
            "\n",
            "('ADJ', 'куп:ROOT/ч:SUFF/их:END')\n",
            "('NOUN', 'купч:ROOT/их:SUFF')\n",
            "\n",
            "простынь\n",
            "('NOUN', 'простын:ROOT/ь:END')\n",
            "('VERB', 'про:PREF/сты:ROOT/н:SUFF/ь:END')\n",
            "\n",
            "('NOUN', 'простын:ROOT/ь:END')\n",
            "('VERB', 'про:PREF/сты:ROOT/нь:SUFF')\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
